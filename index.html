<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Shujian Yu (余书剑)</title>

  <meta name="author" content="Shujian Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Shujian Yu (余书剑)</name>
              </p>
              <p>
                I am an assistant professor in the <a href="https://vu.nl/en/about-vu/more-about/artificial-intelligence-computer-science">Department of Artificial Intelligence</a> at the Vrije Universiteit Amsterdam. I also hold a guest position in the <a href="https://machine-learning.uit.no/home">Machine Learning Group</a> at the UiT - The Arctic University of Norway. 
		I graduated from the University of Florida in the Department of Electrical and Computer Engineering, working with <a href="http://www.cnel.ufl.edu/people/people.php?name=principe">Prof. Jose C. Principe</a>, with a Ph.D. minor in theoretical statistics. Previously, I obtained my BEng degree from the <a href="https://ei.hust.edu.cn/">School of Electronic Information and Communications</a> at the Huazhong University of Science and Technology. I was a research scientist of machine learning at the NEC Laboratories Europe from 2019 to 2021.</p>
                <p>My research interests lie primarily in the intersection of machine learning, information theory, and signal processing, which include topics like information-theoretic learning and machine learning for signal processing. Particularly, I am interested in information-theoretic quantities (such as entropy, mutual information, divergence, etc.) estimation, improving the explainability and generalization of deep neural networks by information-theoretic principles (such as the information bottleneck and the principle of relevant information). I am also interested in brain data analysis (such as EEG and fMRI).
              </p>
<p>I am the recipient of the 2020 <a href="https://www.inns.org/inns-award-recipients">International Neural Networks Society Aharon Katzir Young Investigator Award</a>. I am also selected for the 2023 <a href="https://aaai-23.aaai.org/wp-content/uploads/2023/01/New-Faculty-Highlights-Schedule-with-Room-Number.pdf">AAAI New Faculty Highlights</a>.

              <p style="text-align:center">
                <a href="mailto:s.yu3@vu.nl">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=O8kpnMoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/SJYuCNEL">GitHub</a>&nbsp
              </p>

            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yushujian.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yushujian.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <ul>
			<li>07-05-2025: One paper on dynamic Information Bottleneck for modeling fMRI data is accepted by UAI-25, <a href="https://arxiv.org/abs/2506.08884">link</a>, <a href="https://github.com/marcusstang/InfoDPCCA">code</a>.</li>
			<li>01-05-2025: One paper on multimodal variational autoencoder is accepted by International Conference on Machine Learning (ICML), <a href="https://arxiv.org/abs/2505.01134">link</a>, <a href="https://github.com/rogelioamancisidor/codevae">code</a>.</li>
			<li>14-03-2025: One paper on conditional Cauchy-Schwarz divergence, with applications to biomedical signals (e.g., EEG) and reinforcement learning, is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), <a href="https://arxiv.org/abs/2301.08970">link</a>, <a href="https://github.com/SJYuCNEL/conditional_CS_divergence">code</a>.</li>
			<li>22-01-2025: One paper on rate-distortion explanation of deep neural networks is accepted by ICLR-25, <a href="https://openreview.net/forum?id=Iht4NNVqk0">link</a>, <a href="https://github.com/BuelentUendes/StartGrad">code</a>.</li>
			<li>20-12-2024: Three papers on “State Space Models” and “Cauchy-Schwarz divergence” are accepted by ICASSP-25.</li>
			<li>25-09-2024: One paper on backdoor detection is accepted by NeurIPS-24, <a href="https://arxiv.org/pdf/2405.19928">link</a>, <a href="https://anonymous.4open.science/r/ban-4B32/README.md">code</a>.</li>
			<li>20-08-2024: One paper on Information Bottleneck for interpretable brain disorder diagnosis is accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS), <a href="https://arxiv.org/abs/2205.03612">link</a>, <a href="https://github.com/SJYuCNEL/brain-and-Information-Bottleneck">code</a>.</li>
			<li>02-05-2024: One paper on neural network-based Granger causality is accepted by International Conference on Machine Learning (ICML), <a href="https://arxiv.org/abs/2405.08779">link</a>, <a href="https://github.com/ElleZWQ/JRNGC">code</a>.</li>
			<li>26-04-2024: One paper on Cauchy-Schwarz divergence for domain adaptation is accepted by UAI-24, <a href="https://openreview.net/forum?id=62m7yvkGIY">link</a>, <a href="https://github.com/ywzcode/CS-adv">code</a>.</li>
			<li>27-03-2024: One paper on prototype learning for interpretable brain network-based psychiatric diagnosis and subtyping is accepted by NeuroImage, <a href="https://www.sciencedirect.com/science/article/pii/S1053811924000892">link</a>, <a href="https://github.com/ZKZ-Brain/BPI-GNN">code</a>.</li>
			<li>23-01-2024: One paper on Granger causality for interpretable brain network-based psychiatric diagnosis is accepted by Neural Networks, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024000716">link</a>, <a href="https://github.com/ZKZ-Brain/CI-GNN/">code</a>.</li>
			<li>16-01-2024: Two papers on “Information Bottleneck”, “Cauchy-Schwarz divergence”, and “generalization error bound” are accepted by International Conference on Learning Representations (ICLR), <a href="https://openreview.net/forum?id=7wY67ZDQTE">link1</a>, <a href="https://openreview.net/forum?id=GWSIo2MzuH">link2</a>.</li>
			<li>15-09-2023: One paper on “Information Bottleneck meets Invariant Risk Minimization” for fine-grained image classification is accepted by Computer Vision and Image Understanding, <a href="https://arxiv.org/abs/2306.04893">link</a>.</li>
			<li>15-07-2023: One paper on “minimum error entropy” for transfer learning is accepted by ECAI-23, <a href="https://arxiv.org/abs/2307.08572">link</a>.</li>
			<li>13-06-2023: The slides of our "Information Theory meets Deep Learning" tutorial in ICASSP-23 are available at <a href="https://drive.google.com/file/d/1p_xJVgLlYy15ygLGRyuyp9XVB89gV0go/view">link</a>.</li>
			<li>17-03-2023: One paper is accepted by the IEEE Transactions on Information Theory.</li>
                  <li>27-01-2023: One paper accepted by the IEEE Transactions on Knowledge and Data Engineering.</li>
                  <li>27-12-2022: One paper accepted by the IEEE Transactions on Signal Processing.</li>
                  <li>22-11-2022: I am honored to be selected for the 2023 AAAI New Faculty Highlights.</li>
			<li>19-11-2022: Two papers accepted by AAAI-23.</li>
                </ul>
              </p>
            </td>
          </tr>
        </tbody></table>
     

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
	    <tr>
		<td style="padding:20px;width:100%;vertical-align:center">
		<img src="images/p1.jpg" alt="method" title="A summary of my current research" width="605.4" height="326.4">
		</td>
	    </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td width="100%" valign="middle">
               <br>
		   <font color=red size=3>**Brain Data Analysis**</font>
		   <br>
		   <a href="https://arxiv.org/abs/2301.06574">
                <papertitle>Causal Recurrent Variational Autoencoder for Medical Time Series Generation</papertitle>
              </a>
              <br>
              Hongming Li, <strong>Shujian Yu</strong>, Jose C. Principe
              <br>
              <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023 | <a href="https://github.com/hongmingli1995/CR-VAE">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">	
              <a href="https://arxiv.org/abs/2205.03612">
                <papertitle>BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck</papertitle>
              </a>
              <br>
              Kaizhong Zheng, <strong>Shujian Yu</strong>, Baojuan Li, Robert Jenssen, Badong Chen
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/abs/2301.01642">
                <papertitle>CI-GNN: A Granger Causality-Inspired Graph Neural Network for Interpretable Brain Network-Based Psychiatric Diagnosis</papertitle>
              </a>
              <br>
              Kaizhong Zheng, <strong>Shujian Yu</strong>, Badong Chen
            </td>
          </tr>

	<tr>
		<br>
            <td width="100%" valign="middle">
		  <font color=red size=3>**Matrix-based Entropy Functional**</font>
		  <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8787866">
                <papertitle>Multivariate Extension of Matrix-based Renyi's α-order Entropy Functional</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Luis Gonzalo Sanchez Giraldo, Robert Jenssen, Jose C. Principe
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2020 | <a href="https://drive.google.com/drive/folders/1SlxzEOX8RbnLwCgRyqGwMOL7vuT90Gje">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17288">
                <papertitle>Measuring Dependence with Matrix-based Entropy Functional</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Francesco Alesiani, Xi Yu, Robert Jenssen, Jose C. Principe
              <br>
              <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2021 | <a href="https://github.com/SJYuCNEL/Matrix-based-Dependence">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://www.ijcai.org/proceedings/2020/385">
                <papertitle>Measuring the Discrepancy between Conditional Distributions: Methods, Properties and Applications</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Ammar Shaker, Francesco Alesiani, Jose C. Principe
              <br>
              <em>Proceedings of the International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 2020 | <a href="https://github.com/SJYuCNEL/Bregman-Correntropy-Conditional-Divergence">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10005826">
                <papertitle>Computationally Efficient Approximations for Matrix-Based Rényi's Entropy</papertitle>
              </a>
              <br>
              Tieliang Gong, Yuxin Dong, <strong>Shujian Yu</strong>, Bo Dong
              <br>
              <em>IEEE Transactions on Signal Processing</em>, 2022
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/abs/2211.16784">
                <papertitle>Robust and Fast Measure of Information via Low-rank Representation</papertitle>
              </a>
              <br>
              Yuxin Dong, Tieliang Gong, <strong>Shujian Yu</strong>, Hong Chen, Chen Li
              <br>
              <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023 | <a href="https://github.com/Gamepiaynmo/LRMI">code</a>
            </td>
          </tr>

 	  <tr>
            <td width="100%" valign="middle">
		  <br>
		  <font color=red size=3>**Cauchy-Schwarz Divergence**</font>
		  <br>
              <a href="https://arxiv.org/abs/2301.08970">
                <papertitle>The Conditional Cauchy-Schwarz Divergence with Applications to Time-Series Data and Sequential Decision Making</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Hongming Li, Sigurd Løkse, Robert Jenssen, Jose C. Principe
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://openreview.net/forum?id=7wY67ZDQTE">
                <papertitle>Cauchy-Schwarz Divergence Information Bottleneck for Regression</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Xi Yu, Sigurd Løkse, Robert Jenssen, Jose C. Principe
              <br>
              <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2024 | <a href="https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="">
                <papertitle>Domain Adaptation with Cauchy-Schwarz Divergence</papertitle>
              </a>
              <br>
              Wenzhe Yin,<strong>Shujian Yu</strong>, Yicong Lin, Jie Liu, Jan-Jakob Sonke, Stratis Gavves
	      <br>
              <em>Proceedings of the Uncertainty in Artificial Intelligence (UAI)</em>, 2024
            </td>
          </tr>

           <tr>
            <td width="100%" valign="middle">
		  <br>
		  <font color=red size=3>**Principle of Relevant Information**</font>
		  <br>
              <a href="https://proceedings.mlr.press/v180/yu22c.html">
                <papertitle>Principle of Relevant Information for Graph Sparsification</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Francesco Alesiani, Wenzhe Yin, Robert Jenssen, Jose C. Principe
              <br>
              <em>Proceedings of the Uncertainty in Artificial Intelligence (UAI)</em>, 2022 | <a href="https://github.com/SJYuCNEL/PRI-Graphs">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://link.springer.com/article/10.1007/s10994-021-06011-9">
                <papertitle>Multiscale Principle of Relevant Information for Hyperspectral Image Classification</papertitle>
              </a>
              <br>
              Yantao Wei, <strong>Shujian Yu</strong>, Luis Gonzalo Sanchez Giraldo, Jose C. Principe
              <br>
              <em>Machine Learning</em>, 2021 | <a href="https://github.com/SJYuCNEL/Principle-of-Relevant-Information-and-HSI-Classification">code</a>
            </td>
          </tr>

           <tr>
            <td width="100%" valign="middle">
		  <br>
		  <font color=red size=3>**Deep Neural Networks Explainability (Opening the Black-Box of Deep Learning)**</font>
		  <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608019301352">
                <papertitle>Understanding Autoencoders with Information Theoretic Concepts</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Jose C. Principe
              <br>
              <em>Neural Networks</em>, 2019 | <a href="https://drive.google.com/drive/folders/1e5sIywZfmWp4Dn0WEesb6fqQRM0DIGxZ">code</a>
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://direct.mit.edu/neco/article-abstract/32/1/97/95570/On-Kernel-Method-Based-Connectionist-Models-and?redirectedFrom=fulltext">
                <papertitle>On Kernel Method–based Connectionist Models and Supervised Deep Learning without Backpropagation</papertitle>
              </a>
              <br>
              Shiyu Duan, <strong>Shujian Yu</strong>, Yunmei Chen, Jose C. Principe
              <br>
              <em>MIT Neural Computation</em>, 2020 | <a href="https://github.com/michaelshiyu/kerNET">code</a>
            </td>
          </tr>
		
          <tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8998186">
                <papertitle>Understanding Convolutional Neural Networks with Information Theory: An Initial Exploration</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Kristoffer Wickstrøm, Robert Jenssen, Jose C. Principe
              <br>
              <em>IEEE Transactions on Neural Networks and Learning Systems</em>, 2020 | <a href="https://drive.google.com/drive/folders/1DJYshWIiijKWrFKrztW9FgTzGfMV3D8M">code1 (MATLAB)</a> | <a href="https://github.com/Wickstrom/InfExperiment">code2 (Python)</a>
            </td>
          </tr>

           <tr>
            <td width="100%" valign="middle">
		  <br>
		  <font color=red size=3>**Deep Neural Networks Generalization**</font>
		  <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17288">
                <papertitle>Measuring Dependence with Matrix-based Entropy Functional</papertitle>
              </a>
              <br>
              <strong>Shujian Yu</strong>, Francesco Alesiani, Xi Yu, Robert Jenssen, Jose C. Principe
              <br>
              <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2021 | <a href="https://github.com/SJYuCNEL/Matrix-based-Dependence">code</a>
            </td>
          </tr>

          <tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9414151">
                <papertitle>Deep Deterministic Information Bottleneck with Matrix-based Entropy Functional</papertitle>
              </a>
              <br>
              Xi Yu, <strong>Shujian Yu</strong>, Jose C. Principe
              <br>
              <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021 | <a href="https://github.com/yuxi120407/DIB">code</a>
            </td>
          </tr>

        </tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Great template from <a href="https://jonbarron.info/"> Jon Barron</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
